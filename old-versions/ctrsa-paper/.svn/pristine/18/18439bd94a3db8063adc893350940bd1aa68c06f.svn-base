\section{Introduction} \label{sec:Introdution}

The future development of a scalable quantum computer will allow us to solve in, polynomial time, several problems which are considered intractable for classical computers. Certain fields, such as biology and physics, would certainly benefit from this ``quantum speed up''~\cite{}, however this could be disastrous for security. The security of our current public-key infrastructure is based on the computational hardness of the integer factorization problem (RSA) and the discrete logarithm problem (ECC). These problems, however, will be solved in polynomial time by a machine capable of executing the Shor's algorithm~\cite{}.

To promptly react to the threat, the scientific community started to study, propose, and implement public-key algorithms, to be deployed on classical computers, but based on problems computational difficult to solve also using a quantum computer or a classical computer. This effort is supported by governmental and standardization agencies, which are pushing for new and quantum resistant algorithms. The most notable example of these activities is the open contest that NIST \cite{nistpq} is running for the selection of the next public-key standardised algorithms. The contest started at the end of 2017 and is expected to run for 5 to 7 years.

Approximately seventy algorithms were submitted to the standardisation process, with the large majority of them being based on the hardness of lattice problems. Lattice-based cryptographic algorithms are a class of algorithms which base their security on the hardness of problems such has finding the shortest non-zero vector in a lattice. The reason for such a large number of candidates is because lattice-based algorithms are extremely promising: they can be implemented efficiently and they are extremely versatile, allowing to efficiently implement cryptographic primitives such as, digital signatures, key encapsulation, and identity-based encryption. 

As in the past case for standardising AES~\cite{} and SHA-3~\cite{}, the parameters which will be used for selection include the security of the algorithm and its efficiency when implemented in hardware and software. NIST have also stated that algorithms which can be made robust against physical attacks in an effective and efficient way will be preferred \cite{nistsca}. Thus, it is important, during the scrutiny of the candidates, to explore the potential of implementing these algorithms on a variety of platforms, and to assess the overhead of adding countermeasures against physical attacks.

To this end, this paper concentrates on FrodoKEM, a key encapsulation algorithm submitted to NIST as a potential post-quantum standard. FrodoKEM is a conservative candidates due to its hardness being based on standard lattices, as opposed to Ring-LWE or Module-LWE, as such its has had limited practical evaluations. Thus, we explore the possibility to efficiently implementing it in hardware and we estimate the overhead of protecting against power analysis attacks using first-order masking. To maximize the throughput, while maintaining the area occupation minimal, we rely on a parallelised  implementation of the matrix multiplication. To be parallelized, however, the matrix multiplication requires the use of a smaller and more performant random number generator. We propose to achieve the performance required for the PRNG by using Trivium, which we used instead of AES or cSHAKE.

The rest of the paper is organized as follows. Section~\ref{sec:related} discusses the background and the related works. Section~\ref{sec:design} introduces the proposed hardware architectures and the main design decisions. Section~\ref{sec:results} reports the results obtained while synthesizing our design on reconfigurable hardware and compares our performance against the state-of-the-art. We conclude the paper in Section \ref{sec:conclusions}.